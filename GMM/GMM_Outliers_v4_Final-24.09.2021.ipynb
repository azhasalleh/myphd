{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "26.02.2021 - Modified \"gaussian_mixture_mod5\" \n",
    "- Add new method to get th_resp\n",
    "  - using median of resp\n",
    "  - using center value of min and max of resp ((max - min) /2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Start Dataset :  transfusion\n",
      "\n",
      "k-Means Clustering :\n",
      "Purity Means : 0.7620320855614974 , Std : 0.0\n",
      "Accuracy Means : 0.5571550802139037 , Std : 0.21593021473233168\n",
      "\n",
      "GMM Clustering-random :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jaha\\Anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:276: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  % (init + 1), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity Means : 0.7620320855614974 , Std : 0.0\n",
      "Accuracy Means : 0.4989291443850267 , Std : 0.07622990286355347\n",
      "\n",
      "GMM Clustering-kmeans :\n",
      "Purity Means : 0.7620320855614974 , Std : 0.0\n",
      "Accuracy Means : 0.4649465240641711 , Std : 0.06769612680687848\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.random import RandomState\n",
    "from numpy.random import MT19937\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from pytictoc import TicToc\n",
    "from statistics import mean, stdev\n",
    "# import time\n",
    "\n",
    "def purity_score(y_true, y_pred):\n",
    "    # compute contingency matrix (also called confusion matrix)\n",
    "    contingency_matrix = metrics.cluster.contingency_matrix(y_true, y_pred)\n",
    "#     print(\"\\ncontingency_matrix : \\n\", contingency_matrix)\n",
    "    # return purity\n",
    "    return np.sum(np.amax(contingency_matrix, axis=0)) / np.sum(contingency_matrix)\n",
    "\n",
    "\n",
    "# dataset_labels = [\"transfusion\", \"wilt\", \"breastCancer\", \"heartDisease\", \"adultIncome\", \"australian\", \"japanese\", \"bank\", \"seismicBumps\", \"german\", \n",
    "#                   \"chess\", \"iris\", \"abalone\", \"wallRobot\", \"dermatology\"] \n",
    "m = 'transfusion'\n",
    "\n",
    "print(\"\\n\\nStart Dataset : \",m)\n",
    "#Read dataset\n",
    "dataset = pd.read_csv(\"dataset/\"+m+\".csv\")\n",
    "\n",
    "#Drop Target Column in data using Index\n",
    "X_train = dataset.drop('Target',axis=1)\n",
    "\n",
    "# #How to get Target data\n",
    "y_train =  dataset['Target']\n",
    "# print(np.array(X_train))\n",
    "# print(np.array(y_train))\n",
    "# mt19937 = MT19937()\n",
    "# rs = RandomState(mt19937)\n",
    "# rs_val = rs.standard_normal()\n",
    "# print(\"RandomState :\", rs_val)\n",
    "\n",
    "cov_type = 'full'\n",
    "n_classes = len(np.unique(y_train))   \n",
    "t = TicToc() # create TicToc instance\n",
    "num_repreat = 1000\n",
    "\n",
    "all_purity = []\n",
    "all_accuracy = []\n",
    "all_purity2 = []\n",
    "all_accuracy2 = []\n",
    "all_purity3 = []\n",
    "all_accuracy3 = []\n",
    "print(\"\\nk-Means Clustering :\")\n",
    "for repeat in range (num_repreat):       \n",
    "    t.tic() # Start timer\n",
    "    \n",
    "    #Run the kMeans on current  \n",
    "    \n",
    "    kMeans_cluster = KMeans( n_clusters = n_classes)\n",
    "    kMeans_cluster.fit(X_train)\n",
    "    elapsed_time = t.tocvalue() #Save elapsed time\n",
    "    iter_num = kMeans_cluster.n_iter_\n",
    "    #print(\"kMeans time : \", elapsed_time )   \n",
    "    y_train_pred = kMeans_cluster.predict(X_train)\n",
    "    purity = purity_score(y_train, y_train_pred)\n",
    "    accuracy = accuracy_score(y_train, y_train_pred)\n",
    "#     print(\"Cluster Center :\", kMeans_cluster.cluster_centers_)\n",
    "#     print(\"\\nPurity \",repeat,\":\", purity)\n",
    "#     print(\"Accuracy :\", accuracy)\n",
    "    all_purity.append(purity)\n",
    "    all_accuracy.append(accuracy)\n",
    "# print(\"\\nAll_Purity :\\n\", all_purity)\n",
    "mean_pu = mean(all_purity)\n",
    "std_pu = stdev(all_purity)\n",
    "print(\"Purity Means :\", mean_pu ,\",\",\"Std :\", std_pu)\n",
    "\n",
    "# print(\"\\nAll_accuracy :\\n\", all_accuracy)\n",
    "mean_ac = mean(all_accuracy)\n",
    "std_ac = stdev(all_accuracy)\n",
    "print(\"Accuracy Means :\", mean_ac ,\",\",\"Std :\", std_ac)\n",
    "\n",
    "print(\"\\nGMM Clustering-random :\")\n",
    "for repeat in range (num_repreat):  \n",
    "    #Run the GMM on current\n",
    "    gmm_cluster = GaussianMixture(n_components = n_classes, init_params='random', means_init= None, covariance_type=cov_type, max_iter=60)\n",
    "    t.tic() # Start timer\n",
    "    gmm_cluster.fit(X_train)\n",
    "    elapsed_time = t.tocvalue() #Save elapsed time\n",
    "    iter_num = gmm_cluster.n_iter_\n",
    "#     print(\"GMM time : \", elapsed_time )       \n",
    "    y_train_pred2 = gmm_cluster.predict(X_train)\n",
    "    purity2 = purity_score(y_train, y_train_pred2)\n",
    "    accuracy2 = accuracy_score(y_train, y_train_pred2)\n",
    "#     print(\"Cluster Center :\", kMeans_cluster.cluster_centers_)\n",
    "    all_purity2.append(purity2)\n",
    "    all_accuracy2.append(accuracy2)\n",
    "# print(\"\\nAll_Purity :\\n\", all_purity2)\n",
    "mean_pu2 = mean(all_purity2)\n",
    "std_pu2 = stdev(all_purity2)\n",
    "print(\"Purity Means :\", mean_pu2 ,\",\",\"Std :\", std_pu2)\n",
    "\n",
    "# print(\"\\nAll_accuracy :\\n\", all_accuracy2)\n",
    "mean_ac2 = mean(all_accuracy2)\n",
    "std_ac2 = stdev(all_accuracy2)\n",
    "print(\"Accuracy Means :\", mean_ac2 ,\",\",\"Std :\", std_ac2)\n",
    "\n",
    "print(\"\\nGMM Clustering-kmeans :\")\n",
    "for repeat in range (num_repreat):  \n",
    "    #Run the GMM on current\n",
    "    gmm_cluster2 = GaussianMixture(n_components = n_classes, init_params='kmeans', means_init= None, covariance_type=cov_type, max_iter=50)\n",
    "    t.tic() # Start timer\n",
    "    gmm_cluster2.fit(X_train)\n",
    "    elapsed_time = t.tocvalue() #Save elapsed time\n",
    "    iter_num = gmm_cluster2.n_iter_\n",
    "#     print(\"GMM time : \", elapsed_time )       \n",
    "    y_train_pred3 = gmm_cluster2.predict(X_train)\n",
    "    purity3 = purity_score(y_train, y_train_pred3)\n",
    "    accuracy3 = accuracy_score(y_train, y_train_pred3)\n",
    "#     print(\"Cluster Center :\", kMeans_cluster.cluster_centers_)\n",
    "    all_purity3.append(purity3)\n",
    "    all_accuracy3.append(accuracy3)\n",
    "# print(\"\\nAll_Purity :\\n\", all_purity3)\n",
    "mean_pu3 = mean(all_purity3)\n",
    "std_pu3 = stdev(all_purity3)\n",
    "print(\"Purity Means :\", mean_pu3 ,\",\",\"Std :\", std_pu3)\n",
    "\n",
    "# print(\"\\nAll_accuracy :\\n\", all_accuracy3)\n",
    "mean_ac3 = mean(all_accuracy3)\n",
    "std_ac3 = stdev(all_accuracy3)\n",
    "print(\"Accuracy Means :\", mean_ac3 ,\",\",\"Std :\", std_ac3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47894333805754824 0.47894333805754824\n",
      "0.2045602785530397 0.2045602785530397\n",
      "0.9052140627545171 0.9052140627545171\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import MT19937\n",
    "from numpy.random import RandomState\n",
    "\n",
    "rs = RandomState(12345)\n",
    "mt19937 = MT19937()\n",
    "mt19937.state = rs.get_state()\n",
    "rs2 = RandomState(mt19937)\n",
    "\n",
    "# # Same output\n",
    "rs.standard_normal()\n",
    "rs2.standard_normal()\n",
    "\n",
    "print(rs.standard_normal(),rs2.standard_normal())\n",
    "rs.random()\n",
    "rs2.random()\n",
    "print(rs.random(),rs2.random())\n",
    "\n",
    "rs.standard_exponential()\n",
    "rs2.standard_exponential()\n",
    "print(rs.standard_exponential(),rs2.standard_exponential())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Display full output\n",
    "# from IPython.core.interactiveshell import InteractiveShell\n",
    "# InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from tqdm.auto import tqdm, trange\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>div.output_scroll { height: 40em; }</style>\"))\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import datetime\n",
    "import time\n",
    "from pytictoc import TicToc\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans, MeanShift\n",
    "from fcmeans import FCM\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.mixture_mod import GaussianMixtureMod\n",
    "from sklearn.mixture_mod2 import GaussianMixtureMod2\n",
    "from sklearn.mixture_mod3 import GaussianMixtureMod3\n",
    "from sklearn.mixture_mod4 import GaussianMixtureMod4\n",
    "from sklearn.mixture_mod5 import GaussianMixtureMod5\n",
    "from sklearn.mixture_mod6 import GaussianMixtureMod6\n",
    "from IPython.utils import io\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, adjusted_rand_score, normalized_mutual_info_score, homogeneity_completeness_v_measure,fowlkes_mallows_score,silhouette_score\n",
    "from sklearn.metrics import davies_bouldin_score, v_measure_score\n",
    "from scipy.stats import chi2\n",
    "# opening EXCEL through Code local path in dir\n",
    "import os\n",
    "from pathlib import Path\n",
    "#Funtion declaration\n",
    "def cluster_accuracy(y_true, y_pred):\n",
    "    # compute contingency matrix (also called confusion matrix)\n",
    "    contingency_matrix = metrics.cluster.contingency_matrix(y_true, y_pred)\n",
    "#     print(\"\\ncontingency_matrix : \\n\", contingency_matrix)\n",
    "\n",
    "    # Find optimal one-to-one mapping between cluster labels and true labels\n",
    "    row_ind, col_ind = linear_sum_assignment(-contingency_matrix)\n",
    "    print(\"row_ind : \", row_ind)\n",
    "    print(\"col_ind : \", col_ind)\n",
    "    val1 = contingency_matrix[row_ind, col_ind].sum()\n",
    "    print(\"contingency_matrix[row_ind, col_ind].sum() : \", val1)\n",
    "    val2 = np.sum(contingency_matrix)\n",
    "    print(\"np.sum(contingency_matrix) : \", val2)\n",
    "\n",
    "    # Return cluster accuracy\n",
    "    return contingency_matrix[row_ind, col_ind].sum() / np.sum(contingency_matrix)\n",
    "\n",
    "def purity_score(y_true, y_pred):\n",
    "    # compute contingency matrix (also called confusion matrix)\n",
    "    contingency_matrix = metrics.cluster.contingency_matrix(y_true, y_pred)\n",
    "#     print(\"\\ncontingency_matrix : \\n\", contingency_matrix)\n",
    "    \n",
    "    # return purity\n",
    "    return np.sum(np.amax(contingency_matrix, axis=0)) / np.sum(contingency_matrix) \n",
    "\n",
    "#Get the Clustering Algorithm Performance\n",
    "def cluster_eval(y_true, y_pred, X_train, cluster_label, m, elapsed_time,iter_num):\n",
    "    eval_scores = []\n",
    "    \n",
    "    accuracy = np.mean(y_pred.ravel() == y_true.ravel()) * 100\n",
    "    \n",
    "    purity = purity_score(y_train, y_pred)\n",
    "    micro_f1_score = f1_score(y_true, y_pred, average='micro')\n",
    "    macro_f1_score = f1_score(y_true, y_pred, average='macro')\n",
    "    weighted_f1_score = f1_score(y_true, y_pred, average='weighted')\n",
    "    ari_score = adjusted_rand_score(y_true, y_pred)\n",
    "    nmi_score = normalized_mutual_info_score(y_true, y_pred)\n",
    "#     hc_v_measure = homogeneity_completeness_v_measure(y_true, y_pred)\n",
    "    v_measure = v_measure_score(y_true, y_pred)\n",
    "    fm_score = fowlkes_mallows_score(y_true, y_pred)\n",
    "#     s_score = silhouette_score(X_train, y_pred, metric='euclidean')\n",
    "#     db_score = davies_bouldin_score(X_train, y_pred)\n",
    "#     eval_scores = [m, cluster_label, elapsed_time, iter_num, accuracy, purity, micro_f1_score, macro_f1_score, weighted_f1_score, ari_score, \n",
    "#                    nmi_score, v_measure, fm_score]\n",
    "    eval_scores = [m, cluster_label, elapsed_time, iter_num, purity,  ari_score]\n",
    "    return eval_scores\n",
    "\n",
    "#function to remove outliers using z-score\n",
    "def z_score(data):\n",
    "    data_z = data['mean']\n",
    "    outliers_z = data_z.copy()\n",
    "    mean_z = np.mean(data_z)\n",
    "    std_z =np.std(data_z)\n",
    "    threshold=3.\n",
    "\n",
    "    data['z_score'] = (outliers_z - mean_z)/std_z \n",
    "    outliers_z[(data['z_score'] > threshold)] = np.nan\n",
    "    print('outliers_z : \\n', outliers_z)\n",
    "    #Drop outliers\n",
    "    no_outliers_z = outliers_z.dropna()\n",
    "    print('outliers_z_new : \\n', no_outliers_z)    \n",
    "    return no_outliers_z\n",
    "\n",
    "#function to calculate means \n",
    "def means_init(X, n_components):\n",
    "    n_samples, n_attributes = X.shape\n",
    "    print(\"n_components : \", n_components)\n",
    "    \n",
    "    df_X = pd.DataFrame(X)\n",
    "    \n",
    "    df_X['mean'] = df_X.mean(axis=1)\n",
    "    \n",
    "    no_outliers_z = z_score(df_X)\n",
    "\n",
    "    #Find Max, Min, Diff, Dev\n",
    "    Max = max(no_outliers_z)\n",
    "    Min = min(no_outliers_z)\n",
    "    \n",
    "    diff = Max - Min\n",
    "    dev = diff/n_components\n",
    "    \n",
    "    print('Max: ', Max , 'Min: ', Min)   \n",
    "    print('dev :', dev)\n",
    "    \n",
    "    cluster_range = np.zeros((n_components, 2))\n",
    "    for i in range (n_components):\n",
    "        cluster_range[i] = Min, Min+dev\n",
    "        \n",
    "        Min = Min+dev\n",
    "        df_X['c'+str(i)]=0\n",
    "    print(cluster_range)  \n",
    "\n",
    "    for j in range (n_components):\n",
    "        df_X['c'+str(j)][(df_X['mean']>= cluster_range[j,0]) & (df_X['mean'] < cluster_range[j,1])] = 1\n",
    "\n",
    "    es_init_means = np.zeros((n_components, n_attributes))\n",
    "    for k in range (n_components):    \n",
    "        temp_df_X = df_X.iloc[:, 0:n_attributes][df_X['c'+str(k)] == 1]   \n",
    "        es_init_means[k] = temp_df_X.mean(axis=0) \n",
    "    return es_init_means\n",
    "\"\"\"------------------------------------------------------------------------------------------------------------------------\n",
    "#Main Program - Start here!\n",
    "------------------------------------------------------------------------------------------------------------------------\"\"\"\n",
    "# np.set_printoptions(threshold=sys.maxsize)\n",
    "# pd.set_option('display.max_rows', dataset.shape[0]+1)\n",
    "\n",
    "#Define dataset_labels\n",
    "# dataset_labels = [\"iris\", \"vertebral\",\"new_thyroid\", \"haberman\", \"landsat\", \"seed\", \"ecoli\", \"glass\", \"wine\"]\n",
    "# dataset_labels = [\"ecoli\"]\"glass\",\"vertebral\",\"new_thyroid\",\n",
    "# dataset_labels = [\"wine\", \"new_thyroid\"]\n",
    "# dataset_labels = [\"transfusion\", \"wilt\", \"australian\", \"japanese\", \"iris\"]\n",
    "# dataset_labels = [\"transfusion\", \"wilt\", \"breastCancer\", \"heartDisease\", \"adultIncome\", \"australian\", \"japanese\", \"bank\", \"seismicBumps\", \"german\", \n",
    "#                   \"chess\", \"iris\", \"abalone\", \"wallRobot\", \"dermatology\"] \n",
    "dataset_labels = [\"iris\", \"breastCancer\"]            \n",
    "# dataset_labels = [\"ecoli\", \"seed\", \"glass\"]\n",
    "\n",
    "# skip_Mahal = [\"australian\",\"japanese\", \"seismicBumps\",\"bank\", \"adultIncome\"]\n",
    "\n",
    "# cov_type_labels = [\"full\", \"tied\", \"diag\", \"spherical\"]\n",
    "cov_type_labels = [\"full\"]\n",
    "# cov_type_labels = [\"diag\", \"spherical\"]\n",
    "# Threshold of GMM-EM Response values\n",
    "# th_resp_val = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "# th_resp_val = [1]\n",
    "\n",
    "resp_type_val = ['remove']\n",
    "# resp_type_val = ['donate']\n",
    "# resp_type_val = ['remove', 'donate']\n",
    "\n",
    "# result_labels = [\"Dataset\",\"Algorithm\", \"Elapsed Time\", \"Iter_num\",\"accuracy\", \"purity\", \"micro_f1_score\", \"macro_f1_score\", \"weighted_f1_score\", \"ari_score\", \n",
    "#                 \"nmi_score\", \"hc_v_measure\", \"fm_score\"]\n",
    "result_labels = [\"Dataset\",\"Algorithm\", \"Elapsed Time\", \"Iter_num\", \"purity\", \"ari_score\"]\n",
    "num_repreat = 20\n",
    "\n",
    "absolutePath = []\n",
    "for cov_type in (cov_type_labels):\n",
    "    print(\"\\nStart Cov_Type :\",cov_type)\n",
    "                   \n",
    "    all_scores = []\n",
    "    final_scores = []\n",
    "    all_result = pd.DataFrame()\n",
    "    t = TicToc() # create TicToc instance\n",
    "    # for m in dataset_labels:\n",
    "    for m in tqdm(dataset_labels):\n",
    "        for repeat in range (num_repreat):\n",
    "    \n",
    "        #     enablePrint()\n",
    "            print(\"\\n\\nStart Dataset : \",m)\n",
    "            #Read dataset\n",
    "            dataset = pd.read_csv(\"dataset/\"+m+\".csv\")\n",
    "\n",
    "            #Drop Target Column in data using Index\n",
    "            X_train = dataset.drop('Target',axis=1)\n",
    "\n",
    "            # #How to get Target data\n",
    "            y_train =  dataset['Target']\n",
    "\n",
    "            print(np.array(y_train))\n",
    "\n",
    "            n_classes = len(np.unique(y_train))\n",
    "\n",
    "\n",
    "            #Run the kMeans on current\n",
    "            kMeans_cluster = KMeans(init='random', n_clusters = n_classes, max_iter=20, random_state=0)\n",
    "            t.tic() # Start timer\n",
    "            kMeans_cluster.fit(X_train)\n",
    "            elapsed_time = t.tocvalue() #Save elapsed time\n",
    "            iter_num = kMeans_cluster.n_iter_\n",
    "        #     print(\"kMeans time : \", elapsed_time )   \n",
    "            y_train_pred = kMeans_cluster.predict(X_train)\n",
    "            eval_scores = cluster_eval(y_train, y_train_pred, X_train, \"kMeans\", m, elapsed_time, iter_num )\n",
    "        #     eval_scores = np.append([m],eval_scores,axis=0)  \n",
    "            all_scores = [eval_scores]\n",
    "\n",
    "    #         #Run the GMM on current\n",
    "    #         gmm_cluster = GaussianMixture(n_components = n_classes, init_params='random', means_init= None, covariance_type=cov_type, max_iter=20, random_state=0)\n",
    "    #         t.tic() # Start timer\n",
    "    #         gmm_cluster.fit(X_train)\n",
    "    #         elapsed_time = t.tocvalue() #Save elapsed time\n",
    "    #         iter_num = gmm_cluster.n_iter_\n",
    "    #     #     print(\"GMM time : \", elapsed_time )       \n",
    "    #         y_train_pred = gmm_cluster.predict(X_train)\n",
    "    #         eval_scores = cluster_eval(y_train, y_train_pred, X_train, \"GMM-random_init\", m, elapsed_time, iter_num )\n",
    "    #     #     all_scores += [eval_scores]\n",
    "    #         all_scores += [eval_scores]\n",
    "\n",
    "    #         #Run the GMM on current\n",
    "    #         gmm_cluster = GaussianMixture(n_components = n_classes, init_params='kmeans', means_init= None, covariance_type=cov_type, max_iter=20, random_state=0)\n",
    "    #         t.tic() # Start timer\n",
    "    #         gmm_cluster.fit(X_train)\n",
    "    #         elapsed_time = t.tocvalue() #Save elapsed time\n",
    "    #         iter_num = gmm_cluster.n_iter_\n",
    "    #     #     print(\"GMM time : \", elapsed_time )       \n",
    "    #         y_train_pred = gmm_cluster.predict(X_train)\n",
    "    #         eval_scores = cluster_eval(y_train, y_train_pred, X_train, \"GMM-kmeans_init\", m, elapsed_time, iter_num )\n",
    "    #     #     all_scores += [eval_scores]\n",
    "    #         all_scores += [eval_scores]\n",
    "\n",
    "    #         #Run the GMM on current\n",
    "    #         gmm_cluster = GaussianMixture(n_components = n_classes, init_params='jaha_init_hybrid', means_init= None, covariance_type=cov_type, max_iter=20, random_state=0)\n",
    "    #         t.tic() # Start timer\n",
    "    #         gmm_cluster.fit(X_train)\n",
    "    #         elapsed_time = t.tocvalue() #Save elapsed time\n",
    "    #         iter_num = gmm_cluster.n_iter_\n",
    "    #     #     print(\"GMM time : \", elapsed_time )       \n",
    "    #         y_train_pred = gmm_cluster.predict(X_train)\n",
    "    #         eval_scores = cluster_eval(y_train, y_train_pred, X_train, \"GMM-hybrid_init\", m, elapsed_time, iter_num )\n",
    "    #     #     all_scores += [eval_scores]\n",
    "    #         all_scores += [eval_scores]\n",
    "\n",
    "\n",
    "    #         for resp_type in resp_type_val:\n",
    "    #             gmm_cluster_mod5 = GaussianMixtureMod5(n_components=n_classes, init_params='random', means_init=None, covariance_type=cov_type, max_iter=20, random_state=0, resp_type=resp_type )\n",
    "    #             t.tic() # Start timer\n",
    "    #             gmm_cluster_mod5.fit(X_train)\n",
    "    #             elapsed_time = t.tocvalue() #Save elapsed time\n",
    "    #             iter_num = gmm_cluster_mod5.n_iter_     \n",
    "    #             resp_labels = \"resp center values-random\"+str(resp_type)\n",
    "    #             y_train_pred_mod5 = gmm_cluster_mod5.predict(X_train)\n",
    "    # #             y_train_pred_mod5 = np.choose(y_train_pred_mod5,(4,5,0,1,2,3)).astype(np.int64) \n",
    "    # #             y_train_pred_mod5 = np.flip(y_train_pred_mod5)#5,1,0,3,2,5\n",
    "    #             print('y_train_pred_mod5 :\\n', y_train_pred_mod5)\n",
    "    #             print('y_train :\\n', y_train)\n",
    "    #             eval_scores = cluster_eval(y_train, y_train_pred_mod5, X_train, resp_labels,m, elapsed_time, iter_num)\n",
    "    #             all_scores += [eval_scores]\n",
    "    #         print(\"Finish GaussianMixtureMod5/resp center values-random : \", m, \" : \",resp_type )\n",
    "\n",
    "    #         #Run the GMM-Auto-v2 for every th_resp value on current dataset (using resp center values) - Last tested on 27.01.2021\n",
    "    #         for resp_type in resp_type_val:\n",
    "    #             gmm_cluster_mod5 = GaussianMixtureMod5(n_components=n_classes, init_params='kmeans', means_init=None, covariance_type=cov_type, max_iter=20, random_state=0, resp_type=resp_type )\n",
    "    #             t.tic() # Start timer\n",
    "    #             gmm_cluster_mod5.fit(X_train)\n",
    "    #             elapsed_time = t.tocvalue() #Save elapsed time\n",
    "    #             iter_num = gmm_cluster_mod5.n_iter_     \n",
    "    #             resp_labels = \"resp center values-kmeans\"+str(resp_type)\n",
    "    #             y_train_pred_mod5 = gmm_cluster_mod5.predict(X_train)\n",
    "    # #             y_train_pred_mod5 = np.choose(y_train_pred_mod5,(4,5,0,1,2,3)).astype(np.int64) \n",
    "    # #             y_train_pred_mod5 = np.flip(y_train_pred_mod5)#5,1,0,3,2,5\n",
    "    #             print('y_train_pred_mod5 :\\n', y_train_pred_mod5)\n",
    "    #             print('y_train :\\n', y_train)\n",
    "    #             eval_scores = cluster_eval(y_train, y_train_pred_mod5, X_train, resp_labels,m, elapsed_time, iter_num)\n",
    "    #             all_scores += [eval_scores]\n",
    "    #         print(\"Finish GaussianMixtureMod5/resp center values-kmeans : \", m, \" : \",resp_type)   \n",
    "\n",
    "\n",
    "    #         #Run the GMM-Auto-v2 for every th_resp value on current dataset (using resp center values) - Last tested on 27.01.2021\n",
    "    #         for resp_type in resp_type_val:\n",
    "    #             gmm_cluster_mod5 = GaussianMixtureMod5(n_components=n_classes, init_params='jaha_init_hybrid', means_init=None, covariance_type=cov_type, max_iter=20, random_state=0, resp_type=resp_type )\n",
    "    #             t.tic() # Start timer\n",
    "    #             gmm_cluster_mod5.fit(X_train)\n",
    "    #             elapsed_time = t.tocvalue() #Save elapsed time\n",
    "    #             iter_num = gmm_cluster_mod5.n_iter_     \n",
    "    #             resp_labels = \"resp center values-hybrid_init_\"+str(resp_type)\n",
    "    #             y_train_pred_mod5 = gmm_cluster_mod5.predict(X_train)\n",
    "    # #             y_train_pred_mod5 = np.choose(y_train_pred_mod5,(4,5,0,1,2,3)).astype(np.int64) \n",
    "    # #             y_train_pred_mod5 = np.flip(y_train_pred_mod5)#5,1,0,3,2,5\n",
    "    #             print('y_train_pred_mod5 :\\n', y_train_pred_mod5)\n",
    "    #             print('y_train :\\n', y_train)\n",
    "    #             eval_scores = cluster_eval(y_train, y_train_pred_mod5, X_train, resp_labels,m, elapsed_time, iter_num)\n",
    "    #             all_scores += [eval_scores]\n",
    "    #         print(\"Finish GaussianMixtureMod5/resp center values init_hybrid: \", m, \" : \",resp_type )\n",
    "\n",
    "\n",
    "\n",
    "    #         gmm_cluster_mod6 = GaussianMixtureMod6(n_components=n_classes, init_params='jaha_init_hybrid', means_init=None, covariance_type=cov_type, max_iter=20, random_state=0 )\n",
    "    #         t.tic() # Start timer\n",
    "    #         gmm_cluster_mod6.fit(X_train)\n",
    "    #         elapsed_time = t.tocvalue() #Save elapsed time\n",
    "    #         iter_num = gmm_cluster_mod6.n_iter_     \n",
    "    #         resp_labels = \"outliers based-hybrid_init\"\n",
    "    #         y_train_pred_mod6 = gmm_cluster_mod6.predict(X_train)\n",
    "\n",
    "    #         print('y_train_pred_mod6 :\\n', y_train_pred_mod6)\n",
    "    #         print('y_train :\\n', y_train)\n",
    "    #         eval_scores = cluster_eval(y_train, y_train_pred_mod6, X_train, resp_labels,m, elapsed_time, iter_num)\n",
    "    #         all_scores += [eval_scores]\n",
    "    #         print(\"Finish GaussianMixtureMod6/outliers based-init_hybrid: \", m )\n",
    "\n",
    "\n",
    "            #Change result to Pandas DataFrame\n",
    "            result = pd.DataFrame(all_scores)\n",
    "            all_result = all_result.append(result)\n",
    "            print(\"Finish GaussianMixtureMod : \", m)\n",
    "            \n",
    "    all_result = all_result.append(pd.Series(), ignore_index=True)  \n",
    "    all_result.columns=result_labels    \n",
    "\n",
    "\n",
    "    #Save results to Excel\n",
    "    ts = time.time() \n",
    "    st = datetime.datetime.fromtimestamp(ts).strftime('%H-%M-%S---%d-%m-%Y')\n",
    "    # all_result.to_excel(\"result/All_result_\"+st+\".xlsx\", index=False)\n",
    "    all_result.to_excel(\"result/apr/All_result_\"+cov_type+\"_\"+st+\".xlsx\", index=False)\n",
    "    absolutePath += [Path(\"result/apr/All_result_\"+cov_type+\"_\"+st+\".xlsx\").resolve()]\n",
    "print(\"\\nFinish at \",st)\n",
    "\n",
    "\n",
    "\n",
    "for k in range (len(cov_type_labels)):\n",
    "    filePath = absolutePath[k]\n",
    "    os.system(f'start excel.exe \"{filePath}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Display full output\n",
    "# from IPython.core.interactiveshell import InteractiveShell\n",
    "# InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from tqdm.auto import tqdm, trange\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>div.output_scroll { height: 40em; }</style>\"))\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import datetime\n",
    "import time\n",
    "from pytictoc import TicToc\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans, MeanShift\n",
    "from fcmeans import FCM\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.mixture_mod import GaussianMixtureMod\n",
    "from sklearn.mixture_mod2 import GaussianMixtureMod2\n",
    "from sklearn.mixture_mod3 import GaussianMixtureMod3\n",
    "from sklearn.mixture_mod4 import GaussianMixtureMod4\n",
    "from sklearn.mixture_mod5 import GaussianMixtureMod5\n",
    "from sklearn.mixture_mod6 import GaussianMixtureMod6\n",
    "from IPython.utils import io\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, adjusted_rand_score, normalized_mutual_info_score, homogeneity_completeness_v_measure,fowlkes_mallows_score,silhouette_score\n",
    "from sklearn.metrics import davies_bouldin_score, v_measure_score\n",
    "from scipy.stats import chi2\n",
    "# opening EXCEL through Code local path in dir\n",
    "import os\n",
    "from pathlib import Path\n",
    "#Funtion declaration\n",
    "def cluster_accuracy(y_true, y_pred):\n",
    "    # compute contingency matrix (also called confusion matrix)\n",
    "    contingency_matrix = metrics.cluster.contingency_matrix(y_true, y_pred)\n",
    "#     print(\"\\ncontingency_matrix : \\n\", contingency_matrix)\n",
    "\n",
    "    # Find optimal one-to-one mapping between cluster labels and true labels\n",
    "    row_ind, col_ind = linear_sum_assignment(-contingency_matrix)\n",
    "    print(\"row_ind : \", row_ind)\n",
    "    print(\"col_ind : \", col_ind)\n",
    "    val1 = contingency_matrix[row_ind, col_ind].sum()\n",
    "    print(\"contingency_matrix[row_ind, col_ind].sum() : \", val1)\n",
    "    val2 = np.sum(contingency_matrix)\n",
    "    print(\"np.sum(contingency_matrix) : \", val2)\n",
    "\n",
    "    # Return cluster accuracy\n",
    "    return contingency_matrix[row_ind, col_ind].sum() / np.sum(contingency_matrix)\n",
    "\n",
    "def purity_score(y_true, y_pred):\n",
    "    # compute contingency matrix (also called confusion matrix)\n",
    "    contingency_matrix = metrics.cluster.contingency_matrix(y_true, y_pred)\n",
    "#     print(\"\\ncontingency_matrix : \\n\", contingency_matrix)\n",
    "    \n",
    "    # return purity\n",
    "    return np.sum(np.amax(contingency_matrix, axis=0)) / np.sum(contingency_matrix) \n",
    "\n",
    "#Get the Clustering Algorithm Performance\n",
    "def cluster_eval(y_true, y_pred, X_train, cluster_label, m, elapsed_time,iter_num):\n",
    "    eval_scores = []\n",
    "    \n",
    "    accuracy = np.mean(y_pred.ravel() == y_true.ravel()) * 100\n",
    "    \n",
    "    purity = purity_score(y_train, y_pred)\n",
    "    micro_f1_score = f1_score(y_true, y_pred, average='micro')\n",
    "    macro_f1_score = f1_score(y_true, y_pred, average='macro')\n",
    "    weighted_f1_score = f1_score(y_true, y_pred, average='weighted')\n",
    "    ari_score = adjusted_rand_score(y_true, y_pred)\n",
    "    nmi_score = normalized_mutual_info_score(y_true, y_pred)\n",
    "#     hc_v_measure = homogeneity_completeness_v_measure(y_true, y_pred)\n",
    "    v_measure = v_measure_score(y_true, y_pred)\n",
    "    fm_score = fowlkes_mallows_score(y_true, y_pred)\n",
    "#     s_score = silhouette_score(X_train, y_pred, metric='euclidean')\n",
    "#     db_score = davies_bouldin_score(X_train, y_pred)\n",
    "#     eval_scores = [m, cluster_label, elapsed_time, iter_num, accuracy, purity, micro_f1_score, macro_f1_score, weighted_f1_score, ari_score, \n",
    "#                    nmi_score, v_measure, fm_score]\n",
    "    eval_scores = [m, cluster_label, elapsed_time, iter_num, purity,  ari_score]\n",
    "    return eval_scores\n",
    "\n",
    "#function to remove outliers using z-score\n",
    "def z_score(data):\n",
    "    data_z = data['mean']\n",
    "    outliers_z = data_z.copy()\n",
    "    mean_z = np.mean(data_z)\n",
    "    std_z =np.std(data_z)\n",
    "    threshold=3.\n",
    "\n",
    "    data['z_score'] = (outliers_z - mean_z)/std_z \n",
    "    outliers_z[(data['z_score'] > threshold)] = np.nan\n",
    "    print('outliers_z : \\n', outliers_z)\n",
    "    #Drop outliers\n",
    "    no_outliers_z = outliers_z.dropna()\n",
    "    print('outliers_z_new : \\n', no_outliers_z)    \n",
    "    return no_outliers_z\n",
    "\n",
    "#function to calculate means \n",
    "def means_init(X, n_components):\n",
    "    n_samples, n_attributes = X.shape\n",
    "    print(\"n_components : \", n_components)\n",
    "    \n",
    "    df_X = pd.DataFrame(X)\n",
    "    \n",
    "    df_X['mean'] = df_X.mean(axis=1)\n",
    "    \n",
    "    no_outliers_z = z_score(df_X)\n",
    "\n",
    "    #Find Max, Min, Diff, Dev\n",
    "    Max = max(no_outliers_z)\n",
    "    Min = min(no_outliers_z)\n",
    "    \n",
    "    diff = Max - Min\n",
    "    dev = diff/n_components\n",
    "    \n",
    "    print('Max: ', Max , 'Min: ', Min)   \n",
    "    print('dev :', dev)\n",
    "    \n",
    "    cluster_range = np.zeros((n_components, 2))\n",
    "    for i in range (n_components):\n",
    "        cluster_range[i] = Min, Min+dev\n",
    "        \n",
    "        Min = Min+dev\n",
    "        df_X['c'+str(i)]=0\n",
    "    print(cluster_range)  \n",
    "\n",
    "    for j in range (n_components):\n",
    "        df_X['c'+str(j)][(df_X['mean']>= cluster_range[j,0]) & (df_X['mean'] < cluster_range[j,1])] = 1\n",
    "\n",
    "    es_init_means = np.zeros((n_components, n_attributes))\n",
    "    for k in range (n_components):    \n",
    "        temp_df_X = df_X.iloc[:, 0:n_attributes][df_X['c'+str(k)] == 1]   \n",
    "        es_init_means[k] = temp_df_X.mean(axis=0) \n",
    "    return es_init_means\n",
    "\"\"\"------------------------------------------------------------------------------------------------------------------------\n",
    "#Main Program - Start here!\n",
    "------------------------------------------------------------------------------------------------------------------------\"\"\"\n",
    "# np.set_printoptions(threshold=sys.maxsize)\n",
    "# pd.set_option('display.max_rows', dataset.shape[0]+1)\n",
    "\n",
    "#Define dataset_labels\n",
    "# dataset_labels = [\"iris\", \"vertebral\",\"new_thyroid\", \"haberman\", \"landsat\", \"seed\", \"ecoli\", \"glass\", \"wine\"]\n",
    "# dataset_labels = [\"ecoli\"]\"glass\",\"vertebral\",\"new_thyroid\",\n",
    "# dataset_labels = [\"wine\", \"new_thyroid\"]\n",
    "# dataset_labels = [\"transfusion\", \"wilt\", \"australian\", \"japanese\", \"iris\"]\n",
    "# dataset_labels = [\"transfusion\", \"wilt\", \"breastCancer\", \"heartDisease\", \"adultIncome\", \"australian\", \"japanese\", \"bank\", \"seismicBumps\", \"german\", \n",
    "#                   \"chess\", \"iris\", \"abalone\", \"wallRobot\", \"dermatology\"] \n",
    "dataset_labels = [\"heartDisease\"]            \n",
    "# dataset_labels = [\"ecoli\", \"seed\", \"glass\"]\n",
    "\n",
    "# skip_Mahal = [\"australian\",\"japanese\", \"seismicBumps\",\"bank\", \"adultIncome\"]\n",
    "\n",
    "# cov_type_labels = [\"full\", \"tied\", \"diag\", \"spherical\"]\n",
    "cov_type_labels = [\"full\"]\n",
    "# cov_type_labels = [\"diag\", \"spherical\"]\n",
    "# Threshold of GMM-EM Response values\n",
    "# th_resp_val = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "# th_resp_val = [1]\n",
    "\n",
    "resp_type_val = ['remove']\n",
    "# resp_type_val = ['donate']\n",
    "# resp_type_val = ['remove', 'donate']\n",
    "\n",
    "# result_labels = [\"Dataset\",\"Algorithm\", \"Elapsed Time\", \"Iter_num\",\"accuracy\", \"purity\", \"micro_f1_score\", \"macro_f1_score\", \"weighted_f1_score\", \"ari_score\", \n",
    "#                 \"nmi_score\", \"hc_v_measure\", \"fm_score\"]\n",
    "result_labels = [\"Dataset\",\"Algorithm\", \"Elapsed Time\", \"Iter_num\", \"purity\", \"ari_score\"]\n",
    "\n",
    "absolutePath = []\n",
    "for cov_type in (cov_type_labels):\n",
    "    print(\"\\nStart Cov_Type :\",cov_type)\n",
    "                   \n",
    "    all_scores = []\n",
    "    final_scores = []\n",
    "    all_result = pd.DataFrame()\n",
    "    t = TicToc() # create TicToc instance\n",
    "    # for m in dataset_labels:\n",
    "    for m in tqdm(dataset_labels):\n",
    "    #     enablePrint()\n",
    "        print(\"\\n\\nStart Dataset : \",m)\n",
    "        #Read dataset\n",
    "        dataset = pd.read_csv(\"dataset/\"+m+\".csv\")\n",
    "\n",
    "        #Drop Target Column in data using Index\n",
    "        X_train = dataset.drop('Target',axis=1)\n",
    "\n",
    "        # #How to get Target data\n",
    "        y_train =  dataset['Target']\n",
    "\n",
    "        print(np.array(y_train))\n",
    "\n",
    "        n_classes = len(np.unique(y_train))\n",
    "\n",
    " \n",
    "        #Run the kMeans on current\n",
    "        kMeans_cluster = KMeans(n_clusters = n_classes, max_iter=20, random_state=0)\n",
    "        t.tic() # Start timer\n",
    "        kMeans_cluster.fit(X_train)\n",
    "        elapsed_time = t.tocvalue() #Save elapsed time\n",
    "        iter_num = kMeans_cluster.n_iter_\n",
    "    #     print(\"kMeans time : \", elapsed_time )   \n",
    "        y_train_pred = kMeans_cluster.predict(X_train)\n",
    "        eval_scores = cluster_eval(y_train, y_train_pred, X_train, \"kMeans\", m, elapsed_time, iter_num )\n",
    "    #     eval_scores = np.append([m],eval_scores,axis=0)  \n",
    "        all_scores = [eval_scores]\n",
    " \n",
    "        #Run the GMM on current\n",
    "        gmm_cluster = GaussianMixture(n_components = n_classes, init_params='random', means_init= None, covariance_type=cov_type, max_iter=20, random_state=0)\n",
    "        t.tic() # Start timer\n",
    "        gmm_cluster.fit(X_train)\n",
    "        elapsed_time = t.tocvalue() #Save elapsed time\n",
    "        iter_num = gmm_cluster.n_iter_\n",
    "    #     print(\"GMM time : \", elapsed_time )       \n",
    "        y_train_pred = gmm_cluster.predict(X_train)\n",
    "        eval_scores = cluster_eval(y_train, y_train_pred, X_train, \"GMM-random_init\", m, elapsed_time, iter_num )\n",
    "    #     all_scores += [eval_scores]\n",
    "        all_scores += [eval_scores]\n",
    "        \n",
    "        #Run the GMM on current\n",
    "        gmm_cluster = GaussianMixture(n_components = n_classes, init_params='kmeans', means_init= None, covariance_type=cov_type, max_iter=20, random_state=0)\n",
    "        t.tic() # Start timer\n",
    "        gmm_cluster.fit(X_train)\n",
    "        elapsed_time = t.tocvalue() #Save elapsed time\n",
    "        iter_num = gmm_cluster.n_iter_\n",
    "    #     print(\"GMM time : \", elapsed_time )       \n",
    "        y_train_pred = gmm_cluster.predict(X_train)\n",
    "        eval_scores = cluster_eval(y_train, y_train_pred, X_train, \"GMM-kmeans_init\", m, elapsed_time, iter_num )\n",
    "    #     all_scores += [eval_scores]\n",
    "        all_scores += [eval_scores]\n",
    "              \n",
    "        #Run the GMM on current\n",
    "        gmm_cluster = GaussianMixture(n_components = n_classes, init_params='jaha_init_hybrid', means_init= None, covariance_type=cov_type, max_iter=20, random_state=0)\n",
    "        t.tic() # Start timer\n",
    "        gmm_cluster.fit(X_train)\n",
    "        elapsed_time = t.tocvalue() #Save elapsed time\n",
    "        iter_num = gmm_cluster.n_iter_\n",
    "    #     print(\"GMM time : \", elapsed_time )       \n",
    "        y_train_pred = gmm_cluster.predict(X_train)\n",
    "        eval_scores = cluster_eval(y_train, y_train_pred, X_train, \"GMM-hybrid_init\", m, elapsed_time, iter_num )\n",
    "    #     all_scores += [eval_scores]\n",
    "        all_scores += [eval_scores]\n",
    "\n",
    "                \n",
    "#         for resp_type in resp_type_val:\n",
    "#             gmm_cluster_mod5 = GaussianMixtureMod5(n_components=n_classes, init_params='random', means_init=None, covariance_type=cov_type, max_iter=20, random_state=0, resp_type=resp_type )\n",
    "#             t.tic() # Start timer\n",
    "#             gmm_cluster_mod5.fit(X_train)\n",
    "#             elapsed_time = t.tocvalue() #Save elapsed time\n",
    "#             iter_num = gmm_cluster_mod5.n_iter_     \n",
    "#             resp_labels = \"resp center values-random\"+str(resp_type)\n",
    "#             y_train_pred_mod5 = gmm_cluster_mod5.predict(X_train)\n",
    "# #             y_train_pred_mod5 = np.choose(y_train_pred_mod5,(4,5,0,1,2,3)).astype(np.int64) \n",
    "# #             y_train_pred_mod5 = np.flip(y_train_pred_mod5)#5,1,0,3,2,5\n",
    "#             print('y_train_pred_mod5 :\\n', y_train_pred_mod5)\n",
    "#             print('y_train :\\n', y_train)\n",
    "#             eval_scores = cluster_eval(y_train, y_train_pred_mod5, X_train, resp_labels,m, elapsed_time, iter_num)\n",
    "#             all_scores += [eval_scores]\n",
    "#         print(\"Finish GaussianMixtureMod5/resp center values-random : \", m, \" : \",resp_type )\n",
    "        \n",
    "#         #Run the GMM-Auto-v2 for every th_resp value on current dataset (using resp center values) - Last tested on 27.01.2021\n",
    "#         for resp_type in resp_type_val:\n",
    "#             gmm_cluster_mod5 = GaussianMixtureMod5(n_components=n_classes, init_params='kmeans', means_init=None, covariance_type=cov_type, max_iter=20, random_state=0, resp_type=resp_type )\n",
    "#             t.tic() # Start timer\n",
    "#             gmm_cluster_mod5.fit(X_train)\n",
    "#             elapsed_time = t.tocvalue() #Save elapsed time\n",
    "#             iter_num = gmm_cluster_mod5.n_iter_     \n",
    "#             resp_labels = \"resp center values-kmeans\"+str(resp_type)\n",
    "#             y_train_pred_mod5 = gmm_cluster_mod5.predict(X_train)\n",
    "# #             y_train_pred_mod5 = np.choose(y_train_pred_mod5,(4,5,0,1,2,3)).astype(np.int64) \n",
    "# #             y_train_pred_mod5 = np.flip(y_train_pred_mod5)#5,1,0,3,2,5\n",
    "#             print('y_train_pred_mod5 :\\n', y_train_pred_mod5)\n",
    "#             print('y_train :\\n', y_train)\n",
    "#             eval_scores = cluster_eval(y_train, y_train_pred_mod5, X_train, resp_labels,m, elapsed_time, iter_num)\n",
    "#             all_scores += [eval_scores]\n",
    "#         print(\"Finish GaussianMixtureMod5/resp center values-kmeans : \", m, \" : \",resp_type)   \n",
    "\n",
    " \n",
    "        #Run the GMM-Auto-v2 for every th_resp value on current dataset (using resp center values) - Last tested on 27.01.2021\n",
    "        for resp_type in resp_type_val:\n",
    "            gmm_cluster_mod5 = GaussianMixtureMod5(n_components=n_classes, init_params='jaha_init_hybrid', means_init=None, covariance_type=cov_type, max_iter=20, random_state=0, resp_type=resp_type )\n",
    "            t.tic() # Start timer\n",
    "            gmm_cluster_mod5.fit(X_train)\n",
    "            elapsed_time = t.tocvalue() #Save elapsed time\n",
    "            iter_num = gmm_cluster_mod5.n_iter_     \n",
    "            resp_labels = \"resp center values-hybrid_init_\"+str(resp_type)\n",
    "            y_train_pred_mod5 = gmm_cluster_mod5.predict(X_train)\n",
    "#             y_train_pred_mod5 = np.choose(y_train_pred_mod5,(4,5,0,1,2,3)).astype(np.int64) \n",
    "#             y_train_pred_mod5 = np.flip(y_train_pred_mod5)#5,1,0,3,2,5\n",
    "            print('y_train_pred_mod5 :\\n', y_train_pred_mod5)\n",
    "            print('y_train :\\n', y_train)\n",
    "            eval_scores = cluster_eval(y_train, y_train_pred_mod5, X_train, resp_labels,m, elapsed_time, iter_num)\n",
    "            all_scores += [eval_scores]\n",
    "        print(\"Finish GaussianMixtureMod5/resp center values init_hybrid: \", m, \" : \",resp_type )\n",
    "\n",
    "        \n",
    "        \n",
    "        gmm_cluster_mod6 = GaussianMixtureMod6(n_components=n_classes, init_params='jaha_init_hybrid', means_init=None, covariance_type=cov_type, max_iter=20, random_state=0 )\n",
    "        t.tic() # Start timer\n",
    "        gmm_cluster_mod6.fit(X_train)\n",
    "        elapsed_time = t.tocvalue() #Save elapsed time\n",
    "        iter_num = gmm_cluster_mod6.n_iter_     \n",
    "        resp_labels = \"outliers based-hybrid_init\"\n",
    "        y_train_pred_mod6 = gmm_cluster_mod6.predict(X_train)\n",
    "\n",
    "        print('y_train_pred_mod6 :\\n', y_train_pred_mod6)\n",
    "        print('y_train :\\n', y_train)\n",
    "        eval_scores = cluster_eval(y_train, y_train_pred_mod6, X_train, resp_labels,m, elapsed_time, iter_num)\n",
    "        all_scores += [eval_scores]\n",
    "        print(\"Finish GaussianMixtureMod6/outliers based-init_hybrid: \", m )\n",
    "\n",
    "\n",
    "        #Change result to Pandas DataFrame\n",
    "        result = pd.DataFrame(all_scores)\n",
    "        all_result = all_result.append(result)\n",
    "        print(\"Finish GaussianMixtureMod : \", m)\n",
    "    all_result = all_result.append(pd.Series(), ignore_index=True) \n",
    "    all_result.columns=result_labels    \n",
    "\n",
    "\n",
    "    #Save results to Excel\n",
    "    ts = time.time() \n",
    "    st = datetime.datetime.fromtimestamp(ts).strftime('%H-%M-%S---%d-%m-%Y')\n",
    "    # all_result.to_excel(\"result/All_result_\"+st+\".xlsx\", index=False)\n",
    "    all_result.to_excel(\"result/apr/All_result_\"+cov_type+\"_\"+st+\".xlsx\", index=False)\n",
    "    absolutePath += [Path(\"result/apr/All_result_\"+cov_type+\"_\"+st+\".xlsx\").resolve()]\n",
    "print(\"\\nFinish at \",st)\n",
    "\n",
    "\n",
    "\n",
    "for k in range (len(cov_type_labels)):\n",
    "    filePath = absolutePath[k]\n",
    "    os.system(f'start excel.exe \"{filePath}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main program end here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
