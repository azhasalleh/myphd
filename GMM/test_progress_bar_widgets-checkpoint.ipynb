{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-24-e40cb10cbc99>, line 58)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-24-e40cb10cbc99>\"\u001b[1;36m, line \u001b[1;32m58\u001b[0m\n\u001b[1;33m    dataset_labels = [\"seismicBumps\", \"german\", \"chess\", \"abalone\", \"wallRobot\",\"wilt\"] # Group2 - Done 31.01.2022 --remove bank & adultIncome\u001b[0m\n\u001b[1;37m                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Updated on 21.02.2022\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.utils import io\n",
    "from IPython.display import display\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>div.output_scroll { height: 40em; }</style>\"))\n",
    "from sty import fg, rs\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import RandomState\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans, DBSCAN, MeanShift, SpectralClustering, OPTICS, Birch, AffinityPropagation, estimate_bandwidth\n",
    "from fcmeans import FCM\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.mixture_mod5 import GaussianMixtureMod5\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from pytictoc import TicToc\n",
    "from statistics import mean, stdev\n",
    "from tqdm import tqdm, trange, tqdm_notebook\n",
    "from sklearn.metrics import accuracy_score, adjusted_rand_score\n",
    "# from statmodels import robust\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "def purity_score(y_true, y_pred):\n",
    "    # compute contingency matrix (also called confusion matrix)\n",
    "    contingency_matrix = metrics.cluster.contingency_matrix(y_true, y_pred)\n",
    "#     print(\"\\ncontingency_matrix : \\n\", contingency_matrix)\n",
    "    # return purity\n",
    "    return np.sum(np.amax(contingency_matrix, axis=0)) / np.sum(contingency_matrix)\n",
    "\n",
    "#Get the Clustering Algorithm Performance\n",
    "def cluster_eval(y_true, y_pred, X_train):\n",
    "    eval_scores = []\n",
    "   \n",
    "    accuracy = np.mean(y_pred.ravel() == y_true.ravel()) * 100 \n",
    "    purity = purity_score(y_train, y_pred)\n",
    "    ari_score = adjusted_rand_score(y_true, y_pred)\n",
    "\n",
    "#     eval_scores = [m, cluster_label, elapsed_time, iter_num, purity, ari_score]\n",
    "    eval_scores = [purity, ari_score, elapsed_time, iter_num,]\n",
    "    return eval_scores\n",
    "\n",
    "def animated_marker():     \n",
    "    widgets = ['Loading: ', progressbar.AnimatedMarker()]\n",
    "    bar = progressbar.ProgressBar(widgets=widgets).start()   \n",
    "    for i in range(100):\n",
    "#         time.sleep(0.1)\n",
    "        bar.update(i)\n",
    "#Main Program start here!---------------------------------------------------------------------------------------------------------------------------------------#\n",
    "# dataset_labels = [\"transfusion\", \"breastCancer\", \"heartDisease\", \"australian\", \"japanese\", \"vertebral\", \"haberman\", \"iris\", \"new_thyroid\", \"dermatology\"] # Group1 - Done 22.01.2022\n",
    "# dataset_labels = [\"bank\", \"seismicBumps\", \"german\", \"chess\", \"abalone\", \"wallRobot\",\"wilt\", \"adultIncome\"] # Group2 - Done 22.01.2022\n",
    "dataset_labels = [\"seismicBumps\", \"german\", \"chess\", \"abalone\", \"wallRobot\",\"wilt\"] # Group2 - Done 31.01.2022 --remove bank & adultIncome\n",
    "\n",
    "# dataset_labels = [\"transfusion\", \"wilt\", \"breastCancer\", \"heartDisease\", \"adultIncome\", \"australian\", \"japanese\", \"bank\", \"seismicBumps\", \"german\", \n",
    "#                   \"chess\", \"vertebral\", \"haberman\", \"iris\", \"abalone\", \"new_thyroid\",\"wallRobot\", \"dermatology\",] \n",
    "# dataset_labels = [\"iris\"] \n",
    "# dataset_labels = [\"iris\", \"transfusion\"] \n",
    "\n",
    "# method_labels = [\"KMeans\", 'GMM-random', 'GMM-kMeans', 'GMM-init_hybrid', 'OBGMM']\n",
    "# method_labels = ['DBSCAN','MeanShift', 'Birch', 'OPTICS', 'FCM', 'AffinityPropagation', 'SpectralClustering']\n",
    "method_labels = [\"KMeans\",'GMM-init_hybrid', 'OBGMM', 'DBSCAN','MeanShift', 'FCM', 'AffinityPropagation', 'SpectralClustering']\n",
    "num_methods = 8\n",
    "result_labels = [\"Dataset\",\"Algorithm\", \"purity\", \"purity_std\", \"ari_score\", \"ari_score_std\", \"Elapsed Time\", \"Iter_num\"]\n",
    "\n",
    "cov_type = 'full'\n",
    "t = TicToc() # create TicToc instance\n",
    "num_repeat = 3\n",
    "\n",
    "# Declare All Clustering methods\n",
    "clust1 = 'KMeans(n_clusters = n_classes)'\n",
    "clust2 = \"GaussianMixture(n_components = n_classes, init_params='random', covariance_type='full', max_iter=100)\"\n",
    "clust3 = \"GaussianMixture(n_components = n_classes, init_params='kmeans', covariance_type='full', max_iter=100)\"\n",
    "clust4 = \"GaussianMixture(n_components = n_classes, init_params='jaha_init_hybrid', covariance_type='full', max_iter=100)\"\n",
    "clust5 = \"GaussianMixtureMod5(n_components=n_classes, init_params='jaha_init_hybrid', covariance_type='full', max_iter=100, resp_type='remove')\"\n",
    "clust6 = \"DBSCAN(eps=0.5, min_samples=5, metric='euclidean', metric_params=None, algorithm='auto', leaf_size=30, p=None, n_jobs=None)\"\n",
    "clust7 = \"MeanShift(bandwidth=bandwidth, seeds=None, bin_seeding=True, min_bin_freq=1, cluster_all=True, n_jobs=None, max_iter=100)\"\n",
    "clust8 = \"Birch(n_clusters=n_classes)\"\n",
    "clust9 = \"OPTICS(min_samples=50, xi=.05, min_cluster_size=.05, cluster_method='xi', metric='minkowski', algorithm = 'auto')\"\n",
    "clust10 = \"FCM(n_clusters=n_classes)\"\n",
    "clust11 = \"AffinityPropagation()\"\n",
    "clust12 = \"SpectralClustering(n_clusters = 3, random_state=0)\"\n",
    "\n",
    "# for i in tqdm_notebook(range(4), desc='1st loop'):\n",
    "#     for j in tqdm_notebook(range(100), desc='2nd loop', leave=False):\n",
    "\n",
    "all_result = pd.DataFrame()\n",
    "for m in tqdm_notebook(dataset_labels, desc = 'Overall Progress :'):\n",
    "    #Read dataset\n",
    "    dataset = pd.read_csv(\"dataset/\"+m+\".csv\")\n",
    "    #Drop Target Column in data using Index\n",
    "    X_train = dataset.drop('Target',axis=1)\n",
    "    #Get y_train\n",
    "    y_train =  dataset['Target']\n",
    "    n_classes = len(np.unique(y_train))  \n",
    "    \n",
    "    bandwidth = estimate_bandwidth(X_train, quantile=0.2, n_samples=len(X_train))\n",
    "\n",
    "#     print(\"Start Dataset : \",m)\n",
    "   \n",
    "    all_scores = []\n",
    "\n",
    "    for i, clust,met_label in zip(tqdm_notebook(range(num_methods), desc = m.capitalize()+' dataset :'), [clust1, clust4, clust5, clust6, clust7, clust10, clust11, clust12], method_labels):\n",
    "\n",
    "        for repeat in tqdm_notebook(range(num_repeat), desc = \">>> \"+met_label): \n",
    "            time.sleep(0.1)\n",
    "            animated_marker()\n",
    "#             print(\"Start-Loop = \",repeat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import trange\n",
    "from time import sleep\n",
    "\n",
    "for i in trange(4, desc='1st loop'):\n",
    "    for j in trange(5, desc='2nd loop'):\n",
    "        for k in trange(50, desc='3rd loop', leave=False):\n",
    "            sleep(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "class TqdmExtraFormat(tqdm):\n",
    "    \"\"\"Provides a `total_time` format parameter\"\"\"\n",
    "    @property\n",
    "    def format_dict(self):\n",
    "        d = super(TqdmExtraFormat, self).format_dict\n",
    "        total_time = d[\"elapsed\"] * (d[\"total\"] or 0) / max(d[\"n\"], 1)\n",
    "        d.update(total_time=self.format_interval(total_time) + \" in total\")\n",
    "        return d\n",
    "\n",
    "for i in TqdmExtraFormat(\n",
    "      range(9), ascii=\" .oO0\",\n",
    "      bar_format=\"{total_time}: {percentage:.0f}%|{bar}{r_bar}\"):\n",
    "    if i == 4:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch      4.5█████████████████████████████████| 10/10 [00:01<00:00,  8.94it/s, gen=149, loss=0.773, lst=[1, 2], str=h]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm, trange\n",
    "from random import random, randint\n",
    "from time import sleep\n",
    "\n",
    "with trange(10) as t:\n",
    "    for i in t:\n",
    "        # Description will be displayed on the left\n",
    "        t.set_description('GEN %i' % i)\n",
    "        # Postfix will be displayed on the right,\n",
    "        # formatted automatically based on argument's datatype\n",
    "        t.set_postfix(loss=random(), gen=randint(1,999), str='h',\n",
    "                      lst=[1, 2])\n",
    "        sleep(0.1)\n",
    "\n",
    "with tqdm(total=10, bar_format=\"{postfix[0]} {postfix[1][value]:>8.2g}\",\n",
    "          postfix=[\"Batch\", dict(value=0)]) as t:\n",
    "    for i in range(10):\n",
    "        sleep(0.1)\n",
    "        t.postfix[1][\"value\"] = i / 2\n",
    "        t.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\n",
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\n",
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|████████████████████████████████████████████████████████                            | 2/3 [00:01<00:00,  1.92it/s]\n",
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:02<00:00,  1.49it/s]"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "from tqdm import tqdm\n",
    "\n",
    "values = range(3)\n",
    "with tqdm(total=len(values)) as pbar:\n",
    "    for i in values:\n",
    "        pbar.write('processed: %d' %i)\n",
    "        pbar.update(1)\n",
    "        sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.utils import io\n",
    "def myfunc():\n",
    "    print('Private Message')\n",
    "\n",
    "with io.capture_output() as captured:\n",
    "    myfunc()\n",
    "    print('Hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\x1b[31mText in red\")\n",
    "print(\"\\x1B[1mText in bold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sty import fg, rs\n",
    "# from sty import fg, ef, rs, Style, RgbFg,bg, RgbBg\n",
    "\n",
    "\n",
    "\n",
    "name=\"Enter your name here\" #enter your name here\n",
    "\n",
    "red_color_string = fg.yellow + name + rs.fg\n",
    "print(red_color_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "def myfunc():\n",
    "    print('Private Message')\n",
    "    \n",
    "    \n",
    "myfunc()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "from time import sleep\n",
    "from IPython.utils import io\n",
    "\n",
    "# with io.capture_output() as captured:\n",
    "for i in tqdm_notebook(range(4), desc='1st loop'):\n",
    "    for j in tqdm_notebook(range(100), desc='2nd loop', leave=False):\n",
    "        with io.capture_output() as captured:\n",
    "#     for j in tqdm_notebook(range(100), desc='2nd loop'):\n",
    "\n",
    "            sleep(0.01)\n",
    "            print(\"complete!\", j)\n",
    "\n",
    "print(\"complete!\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]\n",
      " 20%|████████████████▏                                                                | 20/100 [00:01<00:04, 19.71it/s]\n",
      " 30%|████████████████████████▎                                                        | 30/100 [00:02<00:04, 15.21it/s]\n",
      " 40%|████████████████████████████████▍                                                | 40/100 [00:03<00:04, 13.15it/s]\n",
      " 50%|████████████████████████████████████████▌                                        | 50/100 [00:04<00:04, 11.98it/s]\n",
      " 60%|████████████████████████████████████████████████▌                                | 60/100 [00:05<00:03, 11.28it/s]\n",
      " 70%|████████████████████████████████████████████████████████▋                        | 70/100 [00:06<00:02, 10.83it/s]\n",
      " 80%|████████████████████████████████████████████████████████████████▊                | 80/100 [00:07<00:01, 10.53it/s]\n",
      " 90%|████████████████████████████████████████████████████████████████████████▉        | 90/100 [00:08<00:00, 10.32it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:09<00:00, 10.18it/s]"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import *\n",
    "\n",
    "pbar1 = tqdm(total=100, position=1, leave=False)\n",
    "# pbar2 = tqdm(total=200, position=0)\n",
    "\n",
    "for i in range(10):\n",
    "    pbar1.update(10)\n",
    "#     pbar2.update(20)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'tqdm' has no attribute 'notebook'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-05c01f21118a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m.3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtest48\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-05c01f21118a>\u001b[0m in \u001b[0;36mtest48\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtest48\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m   \u001b[1;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotebook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mposition\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Outter'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moutter_range\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moutter_range\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m       \u001b[0mleave\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutter_range\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotebook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mposition\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mleave\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Inner'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'tqdm' has no attribute 'notebook'"
     ]
    }
   ],
   "source": [
    "def test48():\n",
    "  with tqdm.notebook.trange(3, position=0, desc='Outter') as outter_range:\n",
    "    for i in outter_range:\n",
    "      leave = i == len(outter_range) - 1\n",
    "      for _ in tqdm.notebook.trange(3, position=1, leave=leave, desc='Inner'):\n",
    "        sleep(.3)\n",
    "        \n",
    "test48()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Hasif...: 100%|██████████████████████████████████████████████████████████████| 100/100 [00:10<00:00,  9.31it/s]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "  \n",
    "for i in tqdm (range (100), desc=\"Loading Hasif...\"):\n",
    "    time.sleep(0.1)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: \\                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete.\n"
     ]
    }
   ],
   "source": [
    "import progressbar\n",
    "import time\n",
    "from tqdm import tqdm \n",
    "  \n",
    "# Function to create \n",
    "def animated_marker():     \n",
    "    widgets = ['Loading: ', progressbar.AnimatedMarker()]\n",
    "    bar = progressbar.ProgressBar(widgets=widgets).start()   \n",
    "    for i in range(100):\n",
    "#         time.sleep(0.1)\n",
    "        bar.update(i)\n",
    "       \n",
    "          \n",
    "# Driver's code\n",
    "animated_marker()\n",
    "print(\"Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Hasif :: 100%|███████████████████| 100/100 [00:01<00:00, 60.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete.\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "    \n",
    "for i in tqdm (range (100), desc=\"Loading Hasif :\", ascii=False, ncols=75):\n",
    "    time.sleep(0.01)\n",
    "      \n",
    "print(\"Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "  \n",
    "  \n",
    "for i in tqdm (range (101), desc=\"Loading Hasif…\", ascii=False, ncols=75):\n",
    "    time.sleep(0.1)\n",
    "    print(\"Complete.\")\n",
    "      \n",
    "print(\"Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated on 21.02.2022\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>div.output_scroll { height: 40em; }</style>\"))\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import RandomState\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans, DBSCAN, MeanShift, SpectralClustering, OPTICS, Birch, AffinityPropagation, estimate_bandwidth\n",
    "from fcmeans import FCM\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.mixture_mod5 import GaussianMixtureMod5\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from pytictoc import TicToc\n",
    "from statistics import mean, stdev\n",
    "from tqdm.auto import tqdm, trange\n",
    "from sklearn.metrics import accuracy_score, adjusted_rand_score\n",
    "# from statmodels import robust\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "def purity_score(y_true, y_pred):\n",
    "    # compute contingency matrix (also called confusion matrix)\n",
    "    contingency_matrix = metrics.cluster.contingency_matrix(y_true, y_pred)\n",
    "#     print(\"\\ncontingency_matrix : \\n\", contingency_matrix)\n",
    "    # return purity\n",
    "    return np.sum(np.amax(contingency_matrix, axis=0)) / np.sum(contingency_matrix)\n",
    "\n",
    "#Get the Clustering Algorithm Performance\n",
    "def cluster_eval(y_true, y_pred, X_train):\n",
    "    eval_scores = []\n",
    "   \n",
    "    accuracy = np.mean(y_pred.ravel() == y_true.ravel()) * 100 \n",
    "    purity = purity_score(y_train, y_pred)\n",
    "    ari_score = adjusted_rand_score(y_true, y_pred)\n",
    "\n",
    "#     eval_scores = [m, cluster_label, elapsed_time, iter_num, purity, ari_score]\n",
    "    eval_scores = [purity, ari_score, elapsed_time, iter_num,]\n",
    "    return eval_scores\n",
    "\n",
    "#Main Program start here!---------------------------------------------------------------------------------------------------------------------------------------#\n",
    "# dataset_labels = [\"transfusion\", \"breastCancer\", \"heartDisease\", \"australian\", \"japanese\", \"vertebral\", \"haberman\", \"iris\", \"new_thyroid\", \"dermatology\"] # Group1 - Done 22.01.2022\n",
    "# dataset_labels = [\"bank\", \"seismicBumps\", \"german\", \"chess\", \"abalone\", \"wallRobot\",\"wilt\", \"adultIncome\"] # Group2 - Done 22.01.2022\n",
    "# dataset_labels = [\"seismicBumps\", \"german\", \"chess\", \"abalone\", \"wallRobot\",\"wilt\", \"adultIncome\"] # Group2 - Done 31.01.2022 --remove bank & adultIncome\n",
    "\n",
    "# dataset_labels = [\"transfusion\", \"wilt\", \"breastCancer\", \"heartDisease\", \"adultIncome\", \"australian\", \"japanese\", \"bank\", \"seismicBumps\", \"german\", \n",
    "#                   \"chess\", \"vertebral\", \"haberman\", \"iris\", \"abalone\", \"new_thyroid\",\"wallRobot\", \"dermatology\",] \n",
    "dataset_labels = [\"iris\"] \n",
    "# dataset_labels = [\"iris\", \"transfusion\"] \n",
    "\n",
    "# method_labels = [\"KMeans\", 'GMM-random', 'GMM-kMeans', 'GMM-init_hybrid', 'OBGMM']\n",
    "# method_labels = ['DBSCAN','MeanShift', 'Birch', 'OPTICS', 'FCM', 'AffinityPropagation', 'SpectralClustering']\n",
    "method_labels = [\"KMeans\",'GMM-init_hybrid', 'OBGMM', 'DBSCAN','MeanShift', 'FCM', 'AffinityPropagation', 'SpectralClustering']\n",
    "\n",
    "result_labels = [\"Dataset\",\"Algorithm\", \"purity\", \"purity_std\", \"ari_score\", \"ari_score_std\", \"Elapsed Time\", \"Iter_num\"]\n",
    "\n",
    "cov_type = 'full'\n",
    "t = TicToc() # create TicToc instance\n",
    "num_repeat = 3\n",
    "\n",
    "# Declare All Clustering methods\n",
    "clust1 = 'KMeans(n_clusters = n_classes)'\n",
    "clust2 = \"GaussianMixture(n_components = n_classes, init_params='random', covariance_type='full', max_iter=100)\"\n",
    "clust3 = \"GaussianMixture(n_components = n_classes, init_params='kmeans', covariance_type='full', max_iter=100)\"\n",
    "clust4 = \"GaussianMixture(n_components = n_classes, init_params='jaha_init_hybrid', covariance_type='full', max_iter=100)\"\n",
    "clust5 = \"GaussianMixtureMod5(n_components=n_classes, init_params='jaha_init_hybrid', covariance_type='full', max_iter=100, resp_type='remove')\"\n",
    "clust6 = \"DBSCAN(eps=0.5, min_samples=5, metric='euclidean', metric_params=None, algorithm='auto', leaf_size=30, p=None, n_jobs=None)\"\n",
    "clust7 = \"MeanShift(bandwidth=bandwidth, seeds=None, bin_seeding=True, min_bin_freq=1, cluster_all=True, n_jobs=None, max_iter=100)\"\n",
    "clust8 = \"Birch(n_clusters=n_classes)\"\n",
    "clust9 = \"OPTICS(min_samples=50, xi=.05, min_cluster_size=.05, cluster_method='xi', metric='minkowski', algorithm = 'auto')\"\n",
    "clust10 = \"FCM(n_clusters=n_classes)\"\n",
    "clust11 = \"AffinityPropagation()\"\n",
    "clust12 = \"SpectralClustering(n_clusters = 3, random_state=0)\"\n",
    "\n",
    "\n",
    "all_result = pd.DataFrame()\n",
    "for m in tqdm(dataset_labels):\n",
    "    #Read dataset\n",
    "    dataset = pd.read_csv(\"dataset/\"+m+\".csv\")\n",
    "    #Drop Target Column in data using Index\n",
    "    X_train = dataset.drop('Target',axis=1)\n",
    "    #Get y_train\n",
    "    y_train =  dataset['Target']\n",
    "    n_classes = len(np.unique(y_train))  \n",
    "    \n",
    "    bandwidth = estimate_bandwidth(X_train, quantile=0.2, n_samples=len(X_train))\n",
    "\n",
    "    print(\"Start Dataset : \",m)\n",
    "    all_scores = []\n",
    "    for clust,met_label in zip([clust1, clust4, clust5, clust6, clust7, clust10, clust11, clust12], method_labels):\n",
    "#     for clust,met_label in zip([clust1, clust2, clust3, clust4, clust5], method_labels):\n",
    "#     for clust,met_label in zip([clust1, clust2, clust3], method_labels):\n",
    "        met_scores = []\n",
    "        print(\"\\nMethod :\",met_label)\n",
    "        cluster_method = eval(clust)\n",
    "        for repeat in range (num_repeat): \n",
    "            if (repeat == 0):\n",
    "                print(\"Start-Loop = \",repeat)\n",
    "            t.tic() # Start timer\n",
    "            #Run clstering algorithm for related clusteringmethod\n",
    "#             cluster_method = eval(clust)\n",
    "#             print(\"\\nClustering method :\", cluster_method)    \n",
    "            if (met_label == 'DBSCAN' or met_label == 'SpectralClustering'):\n",
    "                y_train_pred = cluster_method.fit_predict(X_train)\n",
    "                elapsed_time = t.tocvalue() #End Timer & Save elapsed time   \n",
    "                iter_num = 0     \n",
    "\n",
    "            elif (met_label == 'FCM'):\n",
    "                cluster_method.fit(X_train)\n",
    "                elapsed_time = t.tocvalue() #End Timer & Save elapsed time \n",
    "                y_train_pred = cluster_method.u.argmax(axis=1)\n",
    "                iter_num = 0     \n",
    "\n",
    "            else:\n",
    "                cluster_method.fit(X_train)\n",
    "#                 print(\"\\nClustering method Fit:\", repeat)  \n",
    "                elapsed_time = t.tocvalue() #End Timer & Save elapsed time\n",
    "                 \n",
    "                iter_num = cluster_method.n_iter_\n",
    "#                 print(\"kMeans time : \", elapsed_time )   \n",
    "                y_train_pred = cluster_method.predict(X_train)\n",
    "            \n",
    "            eval_scores = cluster_eval(y_train, y_train_pred, X_train)\n",
    "            met_scores += [eval_scores]\n",
    "#             print(eval_scores) \n",
    "            if (repeat == num_repeat - 1):\n",
    "                print(\"Finish-Loop = \",repeat)\n",
    "        met_scores = pd.DataFrame(met_scores)\n",
    "#         all_scores.columns=result_labels \n",
    "        mean_scores = met_scores.mean()\n",
    "        std_scores = met_scores.iloc[:,0:2].std()\n",
    "        met_scores = [m, met_label, mean_scores[0], std_scores[0],mean_scores[1], std_scores[1], mean_scores[2], mean_scores[3] ]   \n",
    "        all_scores += [met_scores]\n",
    "        \n",
    "    #Change result to Pandas DataFrame\n",
    "    result = pd.DataFrame(all_scores)\n",
    "    all_result = all_result.append(result)\n",
    "all_result.columns=result_labels   \n",
    "print(\"\\nAll_results: \\n\",all_result) \n",
    "\n",
    "#Save results to Excel\n",
    "ts = time.time() \n",
    "st = datetime.datetime.fromtimestamp(ts).strftime('%H-%M-%S---%d-%m-%Y')\n",
    "# all_result.to_excel(\"result/All_result_\"+st+\".xlsx\", index=False)\n",
    "all_result.to_excel(\"result/new_loop/All_result_\"+st+\"_\"+str(num_repeat)+\"_loops.xlsx\", index=False)\n",
    "filePath = Path(\"result/new_loop/All_result_\"+st+\"_\"+str(num_repeat)+\"_loops.xlsx\", index=False).resolve()\n",
    "print(\"filePath :\", filePath)\n",
    "print(\"\\nFinish at \",st)\n",
    "print(\"Number of repeat :\", num_repeat )\n",
    "\n",
    "os.system(f'start excel.exe \"{filePath}\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
