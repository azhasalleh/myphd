{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>div.output_scroll { height: 40em; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4db3fdbb41fe4986a231e5751d96a9b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Overall Progress :', max=1, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d319703e243440e3af0e648346b78f82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Eegeyestate dataset :', max=6, style=ProgressStyle(descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8a78106077440e3b6bed31dafbe2a19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='>>> KMeans', style=ProgressStyle(description_width='initial')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b3bafc1230f4e1095b331e2980888bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='>>> DBSCAN', style=ProgressStyle(description_width='initial')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb05c0b22f7a46388d146c6ea731c368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='>>> MeanShift', style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "440030d3450c48418cbaf8239c75c38d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='>>> FCM', style=ProgressStyle(description_width='initial')), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e470c28d81894a028c803fb955faf745",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='>>> OBGMM', style=ProgressStyle(description_width='initial'))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13e4490984674314adf387c72fd9499d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='>>>  GMM-init_hybrid', style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "filePath : E:\\MyJupyter\\1.Exp_03\\GMM_outlier\\result\\new_loop\\All_result_11-46-54---02-06-2022_100_loops_eegEyeState.xlsx\n",
      "\n",
      "Finish at  11-46-54---02-06-2022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Updated on 21.02.2022\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.utils import io\n",
    "from IPython.display import display\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>div.output_scroll { height: 40em; }</style>\"))\n",
    "from sty import fg, rs\n",
    "import progressbar\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import RandomState\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans, DBSCAN, MeanShift, SpectralClustering, OPTICS, Birch, AffinityPropagation, estimate_bandwidth\n",
    "from fcmeans import FCM\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.mixture_mod5 import GaussianMixtureMod5\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from pytictoc import TicToc\n",
    "from statistics import mean, stdev\n",
    "from tqdm import tqdm, trange, tqdm_notebook\n",
    "from sklearn.metrics import accuracy_score, adjusted_rand_score\n",
    "# from statmodels import robust\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import timeit\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "def purity_score(y_true, y_pred):\n",
    "    # compute contingency matrix (also called confusion matrix)\n",
    "    contingency_matrix = metrics.cluster.contingency_matrix(y_true, y_pred)\n",
    "#     print(\"\\ncontingency_matrix : \\n\", contingency_matrix)\n",
    "    # return purity\n",
    "    return np.sum(np.amax(contingency_matrix, axis=0)) / np.sum(contingency_matrix)\n",
    "\n",
    "#Get the Clustering Algorithm Performance\n",
    "def cluster_eval(y_true, y_pred, X_train):\n",
    "    eval_scores = []\n",
    "   \n",
    "    accuracy = np.mean(y_pred.ravel() == y_true.ravel()) * 100 \n",
    "    purity = purity_score(y_train, y_pred)\n",
    "    ari_score = adjusted_rand_score(y_true, y_pred)\n",
    "\n",
    "#     eval_scores = [m, cluster_label, elapsed_time, iter_num, purity, ari_score]\n",
    "    eval_scores = [purity, ari_score, elapsed_time, iter_num,]\n",
    "    return eval_scores\n",
    "\n",
    "def animated_marker():     \n",
    "    widgets = ['Processing : ', progressbar.AnimatedMarker()]\n",
    "    bar = progressbar.ProgressBar(widgets=widgets).start()   \n",
    "    for i in range(100):\n",
    "        bar.update(i)\n",
    "        \n",
    "#Main Program start here!---------------------------------------------------------------------------------------------------------------------------------------#\n",
    "# dataset_labels = [\"transfusion\", \"breastCancer\", \"heartDisease\", \"australian\", \"japanese\", \"vertebral\", \"haberman\", \"iris\", \"new_thyroid\", \"dermatology\"] # Group1 - Done 22.01.2022\n",
    "# dataset_labels = [\"bank\", \"seismicBumps\", \"german\", \"chess\", \"abalone\", \"wallRobot\",\"wilt\", \"adultIncome\"] # Group2 - Done 22.01.2022\n",
    "# dataset_labels = [\"seismicBumps\", \"german\", \"chess\", \"abalone\", \"wallRobot\",\"wilt\"] # Group2 - Done 31.01.2022 --remove bank & adultIncome\n",
    "# dataset_labels = [\"seismicBumps\", \"german\", \"chess\", \"abalone\"] # Group2 - Done 01.02.2022\n",
    "# dataset_labels = [\"wallRobot\",\"wilt\"] #Group3 - Done 01.02.2022\n",
    "# dataset_labels = [\"iris\", \"heartDisease\", \"australian\", \"japanese\", \"abalone\", \"chess\"] #Balanced - 26.05.2022 \n",
    "# dataset_labels = [\"vertebral\", \"new_thyroid\", \"haberman\", \"dermatology\", \"breastCancer\", \"transfusion\", \"german\", \"seismicBumps\", \"wilt\", \"wallRobot\"] #Imbalanced 1 - 26.05.2022 \n",
    "# dataset_labels = [\"bank\",\"adultIncome\"] #Imbalanced 1 - 26.05.2022 \n",
    "\n",
    "dataset_labels = [\"eegEyeState\"] \n",
    "\n",
    "# method_labels = [\"KMeans\", 'GMM-random', 'GMM-kMeans', 'GMM-init_hybrid', 'OBGMM']\n",
    "# method_labels = ['DBSCAN','MeanShift', 'Birch', 'OPTICS', 'FCM', 'AffinityPropagation', 'SpectralClustering']\n",
    "method_labels = [\"KMeans\", 'DBSCAN','MeanShift', 'FCM', 'OBGMM',' GMM-init_hybrid'] # [clust1, clust6, clust7, clust10, clust5, clust4]\n",
    "# method_labels = ['SpectralClustering']\n",
    "num_methods = len(method_labels)\n",
    "result_labels = [\"Dataset\",\"Algorithm\", \"purity\", \"purity_std\", \"ari_score\", \"ari_score_std\", \"Elapsed Time\", \"Iter_num\"]\n",
    "\n",
    "cov_type = 'full'\n",
    "t = TicToc() # create TicToc instance\n",
    "num_repeat = 100\n",
    "\n",
    "# Declare All Clustering methods\n",
    "clust1 = 'KMeans(n_clusters = n_classes)'\n",
    "clust2 = \"GaussianMixture(n_components = n_classes, init_params='random', covariance_type='full', max_iter=100)\"\n",
    "clust3 = \"GaussianMixture(n_components = n_classes, init_params='kmeans', covariance_type='full', max_iter=100)\"\n",
    "clust4 = \"GaussianMixture(n_components = n_classes, init_params='jaha_init_hybrid', covariance_type='full', max_iter=100)\"\n",
    "clust5 = \"GaussianMixtureMod5(n_components=n_classes, init_params='jaha_init_hybrid', covariance_type='full', max_iter=100, resp_type='remove')\"\n",
    "clust6 = \"DBSCAN(eps=0.5, min_samples=5, metric='euclidean', metric_params=None, algorithm='auto', leaf_size=30, p=None, n_jobs=None)\"\n",
    "clust7 = \"MeanShift(bandwidth=bandwidth, seeds=None, bin_seeding=True, min_bin_freq=1, cluster_all=True, n_jobs=None, max_iter=100)\"\n",
    "clust8 = \"Birch(n_clusters=n_classes)\"\n",
    "clust9 = \"OPTICS(min_samples=50, xi=.05, min_cluster_size=.05, cluster_method='xi', metric='minkowski', algorithm = 'auto')\"\n",
    "clust10 = \"FCM(n_clusters=n_classes)\"\n",
    "# clust11 = \"AffinityPropagation()\"\n",
    "# clust12 = \"SpectralClustering(n_clusters = 3, random_state=0)\"\n",
    "\n",
    "# for i in tqdm_notebook(range(4), desc='1st loop'):\n",
    "#     for j in tqdm_notebook(range(100), desc='2nd loop', leave=False):\n",
    "\n",
    "all_result = pd.DataFrame()\n",
    "for m in tqdm_notebook(dataset_labels, desc = 'Overall Progress :'):\n",
    "    #Read dataset\n",
    "    dataset = pd.read_csv(\"dataset/\"+m+\".csv\")\n",
    "    #Drop Target Column in data using Index\n",
    "    X_train = dataset.drop('Target',axis=1)\n",
    "    #Get y_train\n",
    "    y_train =  dataset['Target']\n",
    "    n_classes = len(np.unique(y_train))  \n",
    "    \n",
    "    bandwidth = estimate_bandwidth(X_train, quantile=0.2, n_samples=len(X_train))\n",
    "\n",
    "#     print(\"Start Dataset : \",m)\n",
    "   \n",
    "    all_scores = []\n",
    "#     for clust,met_label in zip([clust1, clust4, clust5, clust6, clust7, clust10, clust11, clust12], method_labels):\n",
    "#     for clust,met_label in tqdm_notebook(zip([clust1, clust2, clust3, clust4, clust5], method_labels), desc='Method loop'):\n",
    "#     for clust,met_label in tqdm_notebook(zip([clust1, clust4, clust5, clust6, clust7, clust10], method_labels)\n",
    "#     for clust,met_label in zip([clust1, clust2, clust3], method_labels):\n",
    "    for i, clust,met_label in zip(tqdm_notebook(range(num_methods), desc = m.capitalize()+' dataset :'), [clust1, clust6, clust7, clust10, clust5, clust4], method_labels):\n",
    "        met_scores = []\n",
    "#         print(\"\\nMethod :\",met_label)\n",
    "        with io.capture_output() as captured:\n",
    "            cluster_method = eval(clust)\n",
    "        for repeat in tqdm_notebook(range(num_repeat), desc = \">>> \"+met_label, bar_format=\"{percentage:3.0f}%|{bar}{r_bar}\"): \n",
    "#             if (repeat == 0):\n",
    "#                 print(\"Start-Loop = \",repeat)\n",
    "#             animated_marker()\n",
    "            t.tic() # Start timer\n",
    "            #Run clstering algorithm for related clusteringmethod\n",
    "#             cluster_method = eval(clust)\n",
    "#             print(\"\\nClustering method :\", cluster_method)    \n",
    "            if (met_label == 'DBSCAN' or met_label == 'SpectralClustering'):\n",
    "                with io.capture_output() as captured:\n",
    "                    y_train_pred = cluster_method.fit_predict(X_train)\n",
    "                    elapsed_time = t.tocvalue() #End Timer & Save elapsed time   \n",
    "                    iter_num = 0     \n",
    "\n",
    "            elif (met_label == 'FCM'):\n",
    "                with io.capture_output() as captured:\n",
    "                    cluster_method.fit(X_train)\n",
    "                    elapsed_time = t.tocvalue() #End Timer & Save elapsed time \n",
    "                    y_train_pred = cluster_method.u.argmax(axis=1)\n",
    "                    iter_num = 0     \n",
    "\n",
    "            else:\n",
    "                with io.capture_output() as captured:\n",
    "                    cluster_method.fit(X_train)\n",
    "    #                 print(\"\\nClustering method Fit:\", repeat)  \n",
    "                    elapsed_time = t.tocvalue() #End Timer & Save elapsed time\n",
    "\n",
    "                    iter_num = cluster_method.n_iter_\n",
    "    #                 print(\"kMeans time : \", elapsed_time )   \n",
    "                    y_train_pred = cluster_method.predict(X_train)\n",
    "                       \n",
    "            eval_scores = cluster_eval(y_train, y_train_pred, X_train)\n",
    "            met_scores += [eval_scores]\n",
    "#             print(eval_scores) \n",
    "#             if (repeat == num_repeat - 1):\n",
    "#                 print(\"Finish-Loop = \",repeat)\n",
    "        met_scores = pd.DataFrame(met_scores)\n",
    "#         all_scores.columns=result_labels \n",
    "        mean_scores = met_scores.mean()\n",
    "        std_scores = met_scores.iloc[:,0:2].std()\n",
    "        met_scores = [m, met_label, mean_scores[0], std_scores[0],mean_scores[1], std_scores[1], mean_scores[2], mean_scores[3] ]   \n",
    "        all_scores += [met_scores]\n",
    "        \n",
    "    #Change result to Pandas DataFrame\n",
    "    result = pd.DataFrame(all_scores)\n",
    "    all_result = all_result.append(result)\n",
    "all_result.columns=result_labels   \n",
    "# print(\"\\nAll_results: \\n\",all_result) \n",
    "\n",
    "#Save results to Excel\n",
    "ts = time.time() \n",
    "st = datetime.datetime.fromtimestamp(ts).strftime('%H-%M-%S---%d-%m-%Y')\n",
    "# all_result.to_excel(\"result/All_result_\"+st+\".xlsx\", index=False)\n",
    "all_result.to_excel(\"result/new_loop/All_result_\"+st+\"_\"+str(num_repeat)+\"_loops_eegEyeState.xlsx\", index=False)\n",
    "filePath = Path(\"result/new_loop/All_result_\"+st+\"_\"+str(num_repeat)+\"_loops_eegEyeState.xlsx\", index=False).resolve()\n",
    "print(\"filePath :\", filePath)\n",
    "print(\"\\nFinish at \",st)\n",
    "# print(\"Number of repeat :\", num_repeat )\n",
    "\n",
    "os.system(f'start excel.exe \"{filePath}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5714285714285714"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjusted_rand_score([0, 0, 1, 1], [0, 0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjusted_rand_score([0, 0, 1, 1], [1, 1, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjusted_rand_score([0, 0, 0, 0], [0, 1, 2, 3])\n",
    "adjusted_rand_score([1, 2, 0, 0], [0, 1, 2, 3])\n",
    "rand_score([1, 2, 0, 0], [0, 1, 2, 3])\n",
    "adjusted_rand_score([1, 0, 0, 0], [0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import rand_score, adjusted_rand_score\n",
    "rand_score([0, 0, 1, 1], [1, 1, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_score([0, 0, 1, 2], [0, 0, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_labels = [\"KMeans\",'GMM-init_hybrid', 'OBGMM', 'DBSCAN','MeanShift', 'FCM', 'AffinityPropagation']\n",
    "num_methods = len(method_labels)\n",
    "print(num_methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Problem :\n",
    "AffinityPropagation\n",
    "MemoryError: Unable to allocate 15.2 GiB for an array with shape (45211, 45211) and data type float64"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
